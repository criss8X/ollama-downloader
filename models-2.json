{
    "models": [
        {
            "name": "gemma:7b",
            "size": "5.0GB"
        },
        {
            "name": "qwq:32b",
            "size": "20GB"
        },
        {
            "name": "codegemma:7b",
            "size": "5.0GB"
        },
        {
            "name": "codegemma:2b",
            "size": "1.6GB"
        },
        {
            "name": "deepseek-coder-v2:16b",
            "size": "8.9GB"
        },
        {
            "name": "falcon3:10b",
            "size": "6.3GB"
        },
        {
            "name": "falcon3:1b",
            "size": "1.8GB"
        },
        {
            "name": "gemma3n:e4b",
            "size": "7.5GB"
        },
        {
            "name": "qwen3-coder:30b",
            "size": "19GB"
        }
    ]
}
